#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{fancyhdr}%The first page setting
\fancypagestyle{plain}
{%
  \fancyhf{} % clear all header and footer fields
  \fancyhead[L]{
    LINK\"OPING UNIVERSITY\\
    Avdelningen för Statistik och maskininlärning\\
    Institutionen för datavetenskap
  }
  \fancyhead[R]{Data Mining}
}
%The remaining pages

\fancyhead[RO,LE]{}
\fancyhead[C]{Programming i R}
\fancyhead[LO,RE]{}

 
\end_preamble
\use_default_options true
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language swedish
\language_package auto
\inputencoding auto
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swedish
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Datorlaboration 4
\end_layout

\begin_layout Author
Josef Wilzén
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<prompt=TRUE,eval=TRUE,echo=FALSE>>=
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# Global options
\end_layout

\begin_layout Plain Layout

opts_chunk$set(comment='') 
\end_layout

\begin_layout Plain Layout

options(digits = 5)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section*
Allmänt
\end_layout

\begin_layout Standard
Datorlaborationerna kräver att ni har R och Rstudio installerat.
 
\end_layout

\begin_layout Itemize
Kodmanual: 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.isakhietala.com/teaching/732g12/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset till vissa uppgifter finns 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset


\bar default
.
\end_layout

\begin_layout Itemize

\series bold
ISL
\series default
: An Introduction to Statistical Learning,
\end_layout

\begin_deeper
\begin_layout Itemize
Boken: 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
R-kod till labbar: 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/resources-second-edition"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://cran.r-project.org/web/packages/ISLR2/index.html"
literal "false"

\end_inset

 och 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/resources-second-edition"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
IDM
\series default
: Introduction to Data Mining
\end_layout

\begin_deeper
\begin_layout Itemize
Kod till boken finns här
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "Sample chapters"
target "https://www-users.cse.umn.edu/~kumar001/dmbook/index.php#chapters"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Dataset till vissa uppgifter finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset

.
 mnist data finns på 
\begin_inset CommandInset href
LatexCommand href
name "Lisam"
target "https://liuonline.sharepoint.com/:f:/r/sites/Lisam_732G12_2021HT_HZ/CourseDocuments/Data?csf=1&web=1&e=ROyENF"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
Notera att ni inte behöver göra alla delar på alla uppgifter.
 Det viktiga är att ni får en förståelse för de olika principerna och modellerna
 som avhandlats.
 Dessa uppgifter ska inte lämnas in, utan är till för er övning.
 
\end_layout

\begin_layout Subsection*
Datauppdelning
\end_layout

\begin_layout Standard
För att motverka överanpassning bör ni dela upp data till träning-, validering-,
 (och testmängd).
 Detta kan göras med 
\family typewriter
createDataPartition()
\family default
 från 
\family typewriter
caret
\family default
-paketet.
 Argument till den funktionen som är av vikt här är 
\begin_inset Formula $p$
\end_inset

 som hur stor andel av observationerna som ska användas till träningsmängden.
 Ni kan också använda 
\family typewriter
subset()
\family default
 för att göra detta också, men det blir svårare att tydligt ange de observatione
r som ska tilldelas till valideringsmängden.
 Denna uppdelning ska ske slumpmässigt.
 Notera att om en testmängd ska skapas måste uppdelningen ske en gång till
 från valideringsmängden.
\end_layout

\begin_layout Section*
Keras
\end_layout

\begin_layout Itemize

\lang english
Se 
\begin_inset CommandInset href
LatexCommand href
name "CHEAT SHEET"
target "https://raw.githubusercontent.com/rstudio/cheatsheets/master/keras.pdf"
literal "false"

\end_inset

 för Keras.
 Dokumentation för keras finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/guide/"
literal "false"

\end_inset

 och 
\bar under
\lang swedish

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/reference/keras/"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Utvärdering vid klassificering kan göras med funktionen 
\begin_inset CommandInset href
LatexCommand href
name "class_evaluation_keras()"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/class_evaluation_keras.R"
literal "false"

\end_inset

.
\end_layout

\begin_layout Section*
Del 1: Optimiering av neurala nätverk
\end_layout

\begin_layout Standard
Här kommer vi utgå från Fashion MNIST-data, kolla 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/"
literal "false"

\end_inset


\bar default
.
 Läs in datamaterialet och se till att ha koll på vad det är för sorts data.
 Nu ska ni testa olika inställningar på optimeringen.
\end_layout

\begin_layout Enumerate
Definera följande modell i keras:
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

<<prompt=TRUE,eval=FALSE,comment=''>>=
\end_layout

\begin_layout Plain Layout

model <- keras_model_sequential() 
\end_layout

\begin_layout Plain Layout

model %>%   
\end_layout

\begin_layout Plain Layout

layer_flatten(input_shape = c(28, 28)) %>%   
\end_layout

\begin_layout Plain Layout

layer_dense(units = 128, activation = 'relu') %>%
\end_layout

\begin_layout Plain Layout

layer_dense(units = 128, activation = 'relu') %>%     
\end_layout

\begin_layout Plain Layout

layer_dense(units = 10, activation = 'softmax')
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Fixera antal epoker till 20.
 Sätt den globala learning rate till 0.01.
 Sätt batchstorlek till 128.
\end_layout

\begin_layout Enumerate
Hur många parametrar har modellen?
\end_layout

\begin_layout Enumerate
Testa nu följande inställningar.
 Undersök tränings- och valideringsdata under träning och utvärdera på testdata.
 
\series bold
Tips
\series default
: titta 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/reference/keras/"
literal "false"

\end_inset


\bar default
 vid behov.
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta modellen med vanlig SGD
\end_layout

\begin_layout Enumerate
Skatta modellen med Adam algoritmen.
 Använd defaultvärden på övriga hyperparametrar.
 
\end_layout

\begin_layout Enumerate
Skatta modellen med RMSPROP algoritmen.
 Använd defaultvärden på övriga hyperparametrar.
 
\end_layout

\begin_layout Enumerate
Vilken metod är ni mest nöjd med?
\end_layout

\end_deeper
\begin_layout Enumerate
Gör om 4) men med batchstorlek 64 och 256.
 Hur påverkar det optimeringen?
\end_layout

\begin_layout Enumerate
Välj batchstorlek 128 och SGD.
 Ändra learning rate till 1 och 0.0001, vad händer?
\end_layout

\begin_layout Enumerate
Upprepa 6) men med Adam eller RMSPROP
\end_layout

\begin_layout Enumerate
Välj batchstorlek 128 och SGD.
 Testa att ändra startvärdena.
 Detta görs i lagerfunktionerna.
 Kolla i dokumentationen hur ni ska göra.
 Testa att låta startvärdena vara väldigt små (men ej exakt noll) och rätt
 stora.
 Hur blir resultatet?
\end_layout

\begin_layout Enumerate
Välj en metod från 4) och skatta modellen med 40 epoker.
\end_layout

\begin_layout Enumerate
Av alla metoder för optimering ni testat, vad tycker ni har funkat bäst?
 Har det varit stor skillnad?
\end_layout

\begin_layout Section*
Del 2: Neurala nätverk regularisering
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/"
literal "false"

\end_inset


\bar default
.
 
\end_layout

\begin_layout Enumerate
IMDB dataset: Ni kommer jobba med ett binärt klassificeringsproblem.
 För bakgrund på datasetet, se 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_text_classification/"
literal "false"

\end_inset


\bar default
.
\end_layout

\begin_layout Enumerate
Hur många parametrar är det i de baseline model, smaller model och bigger
 model? Hur relaterar det till modellernas kapacitet?
\end_layout

\begin_layout Enumerate
Hur bra tycker ni att L2 regularisering och dropout funkar för baseline
 model?
\end_layout

\begin_layout Enumerate
Utgå från baseline model, testa förändringarna nedan.
 Utvärdera valideringsdata med plottar lämpliga utvärderingsmått.
\end_layout

\begin_deeper
\begin_layout Enumerate
L2 regularisering, men med ett annat värde på hyperparametern
\end_layout

\begin_layout Enumerate
Kombinera L2 regularisering och dropout
\end_layout

\begin_layout Enumerate
L1 regularisering, men med minst två olika värden på hyperparametern
\end_layout

\begin_layout Enumerate
Jämför med en modell utan tidigare nämd regularisering
\end_layout

\end_deeper
\begin_layout Section*
Del 3: Mer regularisering
\end_layout

\begin_layout Standard
Ni ska nu modellera datasetet det simulerade datasetet 
\begin_inset Quotes eld
\end_inset

NN_reg_data.csv
\begin_inset Quotes erd
\end_inset

 med neurala nätverk.
 Datasetet har en prediktor, x och y har ett icke-linjärt samband med y.
 
\end_layout

\begin_layout Itemize
Läs in datamaterialet i R.
\end_layout

\begin_layout Itemize
Det finns tre olika y-variabler:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
y_true
\family default
: det sanna värdet på y
\end_layout

\begin_layout Itemize

\family typewriter
y_less_noise
\family default
/
\family typewriter
y_more_noise
\family default
: 
\family typewriter
y_true
\family default
 + olika nivåer av brus.
\end_layout

\end_deeper
\begin_layout Standard
Ni analyserade detta dataset i förra laborationen.
 
\family typewriter
y_true
\family default
 är en funktion som varierar mjukt över x variablen.
 Målet är nu att se om ni kan anpassa en funktion som varierar mer mjukt
 med hjälp av regularisering.
\end_layout

\begin_layout Enumerate
Plotta de olika 
\begin_inset Formula $y$
\end_inset

 mot 
\begin_inset Formula $x$
\end_inset

.
 Hur ser sambandet ut?
\end_layout

\begin_layout Enumerate
Börja med att ha 
\family typewriter
y_less_noise
\family default
 som er responsvariabel.
\end_layout

\begin_layout Enumerate
Dela upp data i träning/test (80/20) slumpmässigt
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta neurala nätverk med arkitekturerna nedan.
 Testa att lägga till olika typer av regularisering.
 Ni kan ha olika typer av regularisering för de olika modellerna.
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Hur presterar modellerna på träning och testdata?
\end_layout

\begin_layout Enumerate
Jämför med fallet utan regularisering (se era resultat på laboration 3)
\end_layout

\begin_layout Enumerate
Gör scatterplot med obserade x och y.
 Lägg till anpassade värden för träning och test (ha olika färger för de
 olika fallen).
 Får ni mer mjukt varierande anpassade värden? 
\end_layout

\end_deeper
\begin_layout Enumerate
Dela upp data i träning/test, där de 20% sista observationerna är testmängden
 (alltså de längst åt höger i era plottar) och resterande i träningsdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta neurala nätverk med arkitekturerna nedan.
 Testa att lägga till olika typer av regularisering.
 Ni kan ha olika typer av regularisering för de olika modellerna.
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Hur presterar modellerna på träning och testdata?
\end_layout

\begin_layout Enumerate
Jämför med fallet utan regularisering (se era resultat på laboration 3)
\end_layout

\begin_layout Enumerate
Gör scatterplot med obserade x och y.
 Lägg till anpassade värden för träning och test (ha olika färger för de
 olika fallen).
 Får ni mer mjukt varierande anpassade värden?
\end_layout

\end_deeper
\begin_layout Enumerate
Kolla på era resulat i 3) och 4), funkar regulariseringen som ni föreslår?
 Lyckas ni anpassa en funktion som varierar mer mjukt med hjälp regulariseringen
, jämfört med om ni inte har någon regulariseringen?
\end_layout

\begin_layout Enumerate
Upprepa 3) och 4) fast använd 
\family typewriter
y_more_noise
\family default
.
 Nu finns det mer brus i data, så nu blir det viktigare med att ha en lämplig
 regularisering för att inte överanpassa.
 Jämför med fallet 
\family typewriter
y_less_noise
\family default
.
\end_layout

\begin_layout Enumerate
Tycker ni att neurala nätverk är en lämplig modellklas för detta dataset?
 
\end_layout

\begin_layout Section*
Del 4: Faltade nätverk
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/advanced/images/cnn/"
literal "false"

\end_inset


\bar default
.
 Ni ska här jobba med CIFAR10 datasetet, som är ett klassiskt datasets inom
 maskininlärning.
 För mer info,se 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://www.cs.toronto.edu/~kriz/cifar.html"
literal "false"

\end_inset


\bar default
 och 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://en.wikipedia.org/wiki/CIFAR-10"
literal "false"

\end_inset


\bar default
.
\end_layout

\begin_layout Standard
Notera att detta är färgbilder som har tre kanaler (grön, röd, blå) och
 att beräkningarna blir mycket tyngre.
\end_layout

\begin_layout Enumerate
Beroende på hårdvaran i er dator så kan det vara bra att minska ner storleken
 på datasetet.
 Testa att börja med hälften av observationerna.
 Sedan kan ni använda fler om er dator klarar av det.
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

<<prompt=TRUE,eval=FALSE,comment=''>>=
\end_layout

\begin_layout Plain Layout

cifar0 <- dataset_cifar10() 
\end_layout

\begin_layout Plain Layout

no_obs<-dim(cifar0$train$y)[1] 
\end_layout

\begin_layout Plain Layout

no_obs_test<-dim(cifar0$test$y)[1] 
\end_layout

\begin_layout Plain Layout

set.seed(34) 
\end_layout

\begin_layout Plain Layout

index<-base::sample(no_obs,size = no_obs/2) 
\end_layout

\begin_layout Plain Layout

index2<-base::sample(no_obs_test,size = no_obs_test/2) 
\end_layout

\begin_layout Plain Layout

cifar<-cifar0
\end_layout

\begin_layout Plain Layout

cifar$train$x<-cifar0$train$x[index,,,] 
\end_layout

\begin_layout Plain Layout

cifar$train$y<-cifar0$train$y[index,]
\end_layout

\begin_layout Plain Layout

cifar$test$x<-cifar0$test$x[index2,,,] 
\end_layout

\begin_layout Plain Layout

cifar$test$y<-cifar0$test$y[index2,] 
\end_layout

\begin_layout Plain Layout

rm(cifar0)
\end_layout

\begin_layout Plain Layout

# kolla så att klasserna är hyfsat balanserade: 
\end_layout

\begin_layout Plain Layout

table(cifar$train$y) 
\end_layout

\begin_layout Plain Layout

table(cifar$test$y)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Vad är det för sorts data ni jobbar med här? Hur många obs? Hur stora bilder?
 Vilka klasser finns?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen (OBS kan ta lång tid).
 Hur många parameterar har den?
\end_layout

\begin_layout Enumerate
Hur presterar modellen på testdata? Beräkna förväxlingsmatrisen för testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Vilken klass var lättast att klassificera?
\end_layout

\begin_layout Enumerate
Vilken klass var svårat?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Ändra de faltade lagren: 
\end_layout

\begin_deeper
\begin_layout Enumerate
Antal lager, varning: ta ej för många 
\end_layout

\begin_layout Enumerate
Ändra antal och storlek på 
\family typewriter
filters
\family default
 i faltade lagren, varning: ta ej för många
\end_layout

\begin_layout Enumerate
Ändra 
\family typewriter
pool_size
\family default
 i pooling-lagren.
\end_layout

\begin_layout Enumerate
Testa average pooling
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att modifiera de fullt kopplade lagren.
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra optimeringen
\end_layout

\begin_layout Enumerate
Hur presterar den bästa modellen som ni lyckas hitta?
\end_layout

\begin_layout Enumerate
Gå in 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://benchmarks.ai/"
literal "false"

\end_inset


\bar default
 och se hur de bästa modellerna presterar på CIFAR10 och MNIST.
\end_layout

\begin_layout Section*
Del 5: Mer faltade nätverk
\end_layout

\begin_layout Standard
Återvänd till Fashion MNIST-data, kolla 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/"
literal "false"

\end_inset


\bar default
.
 Läs in datamaterialet och se till att ha koll på vad det är för sorts data.
\end_layout

\begin_layout Enumerate
Skapa följande modeller:
\end_layout

\begin_deeper
\begin_layout Enumerate
Faltat lager + pooling + två fullt kopplade lager
\end_layout

\begin_layout Enumerate
Faltat lager + pooling + faltat lager + pooling + två fullt kopplade lager
\end_layout

\begin_layout Enumerate
En egen kombination av lager, men med minst ett faltat lager.
\end_layout

\end_deeper
\begin_layout Enumerate
Skatta de föreslagna modellerna.
 Hur många parameterar har de?
\end_layout

\begin_layout Enumerate
Hur presterar modellerna på testdata? Beräkna förväxlingsmatrisen för testdata
 för de olika modellerna.
\end_layout

\begin_deeper
\begin_layout Enumerate
Vilken klass var lättast att klassificera?
\end_layout

\begin_layout Enumerate
Vilken klass var svårat?
\end_layout

\end_deeper
\begin_layout Enumerate
Om ni vill: testa att lägga till någon regularisering till den bästa modellen
 i 1).
 Hur blir prediktionen på testdata?
\end_layout

\begin_layout Enumerate
Jämför med er bästa modell med bara fullt kopplade lager på detta dataset.
 Vilken presterar bäst? Hur stor är skillnaden? Hur skiljer sig antalet
 parametrar åt?
\end_layout

\end_body
\end_document
