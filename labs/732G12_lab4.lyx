#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{fancyhdr}%The first page setting
\fancypagestyle{plain}
{%
  \fancyhf{} % clear all header and footer fields
  \fancyhead[L]{
    LINK\"OPING UNIVERSITY\\
    Avdelningen för Statistik\\
    Institutionen för datavetenskap
  }
  \fancyhead[R]{Programming i R}
}
%The remaining pages

\fancyhead[RO,LE]{}
\fancyhead[C]{Programming i R}
\fancyhead[LO,RE]{}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language swedish
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swedish
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Datorlaboration 4
\end_layout

\begin_layout Author
Josef Wilzén
\end_layout

\begin_layout Standard
\align center
732G12 Data Mining HT2020
\end_layout

\begin_layout Section*
Allmänt
\end_layout

\begin_layout Standard
Datorlaborationerna kräver att ni har R och Rstudio installerat.
 
\end_layout

\begin_layout Itemize
Kodmanual: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.isakhietala.com/teaching/732g12/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset till vissa uppgifter finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
ISL
\series default
: An Introduction to Statistical Learning, 
\end_layout

\begin_deeper
\begin_layout Itemize
Allmän info: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Boken: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
R-kod till labbar: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/code.html"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/data.html"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
Notera att ni inte behöver göra alla delar på alla uppgifter.
 Det viktiga är att ni får en förståelse för de olika principerna och modellerna
 som avhandlats.
 Dessa uppgifter ska inte lämnas in, utan är till för er övning.
 
\end_layout

\begin_layout Subsection*
Datauppdelning
\end_layout

\begin_layout Standard
För att motverka överanpassning bör ni dela upp data till träning-, validering-,
 (och testmängd).
 Detta kan göras med 
\family typewriter
createDataPartition()
\family default
 från 
\family typewriter
caret
\family default
-paketet.
 Argument till den funktionen som är av vikt här är 
\begin_inset Formula $p$
\end_inset

 som hur stor andel av observationerna som ska användas till träningsmängden.
 Ni kan också använda 
\family typewriter
subset()
\family default
 för att göra detta också, men det blir svårare att tydligt ange de observatione
r som ska tilldelas till valideringsmängden.
 Denna uppdelning ska ske slumpmässigt.
 Notera att om en testmängd ska skapas måste uppdelningen ske en gång till
 från valideringsmängden.
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 1: Optimiering av neurala nätverk
\end_layout

\begin_layout Standard
Här kommer vi utgå från Fashion MNIST-data, kolla 
\bar under

\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/"
literal "false"

\end_inset


\bar default
.
 Läs in datamaterialet och se till att ha koll på vad det är för sorts data.
 Nu ska ni testa olika inställningar på optimeringen.
\end_layout

\begin_layout Itemize
Mnist model
\end_layout

\begin_layout Itemize
Fixera antal epoker till 30 
\end_layout

\begin_layout Itemize
Testa olika optimerare
\end_layout

\begin_deeper
\begin_layout Itemize
batchstorlek två stycken
\end_layout

\begin_layout Itemize
SGD
\end_layout

\begin_layout Itemize
ADAM
\end_layout

\begin_layout Itemize
RMSPROP
\end_layout

\end_deeper
\begin_layout Part*
Del 2: Neurala nätverk regularisering
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
IMDB dataset: Ni kommer jobba med ett binärt klassificeringsproblem.
 För bakgrund på datasetet, se 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_text_classification/"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Hur många parametrar är det i de baseline model, smaller model och bigger
 model? Hur relaterar det till modellernas kapacitet?
\end_layout

\begin_layout Enumerate
Hur bra tycker du att L2 regularisering och dropout funkar för baseline
 model?
\end_layout

\begin_layout Enumerate
Utgå från baseline model, testa förändringarna nedan.
 Utvärdera med plottar på valideringsdata och undersök precisionen på testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
L2 regularisering, men med ett annat värde på hyperparametern
\end_layout

\begin_layout Enumerate
Kombinera L2 regularisering och dropout
\end_layout

\begin_layout Enumerate
L1 regularisering, men med minst två olika värden på hyperparametern
\end_layout

\begin_layout Enumerate
Jämför med en modell utan tidigare nämd regularisering
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 3: Mer regularisering
\end_layout

\begin_layout Standard
Regession + regularisering
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 4: Faltade nätverk
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/advanced/images/cnn/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Vad är det för sorts data ni jobbar med här? Hur många obs? Hur stora bilder?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen.
 Hur många parameterar har den?
\end_layout

\begin_layout Enumerate
Hur presterar modellen på testdata? Beräkna förväxlingsmatrisen för testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Vilken klass var lättast att klassificera?
\end_layout

\begin_layout Enumerate
Vilken klass var svårat?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Ändra antalet neuroner i lagren
\end_layout

\begin_layout Enumerate
Testa att lägga till fler lager.
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra optimeringen
\end_layout

\begin_deeper
\begin_layout Enumerate
antalet epoker
\end_layout

\begin_layout Enumerate
batchstorlekek
\end_layout

\end_deeper
\begin_layout Enumerate
Hur presterar den bästa modellen som ni lyckas hitta?
\end_layout

\begin_layout Enumerate
Se denna video: 
\begin_inset CommandInset href
LatexCommand href
name "Parameters vs Hyperparameters"
target "https://www.youtube.com/watch?v=VTE2KlfoO3Q"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 4: Mer faltade nätverk
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_regression/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Vad är det för data? Hur många förklarande variabler? Hur många observationer?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen.
 Hur många parameterar har den?
\end_layout

\begin_deeper
\begin_layout Enumerate
Hur bra blir modellen på testdata?
\end_layout

\begin_layout Enumerate
Vilken kostnadsfunktion används?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen och utvärdera resultatet på testdata.
\end_layout

\begin_layout Enumerate
Testa att ändra optimeringen och utvärdera resultatet på testdata.
\end_layout

\begin_layout Enumerate
Skatta en Random forest-modell på samma dataset och utvärdera resultatet
 på testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Fungerar Random forest bättre eller sämre än neurala nätverk på dettta dataset?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 4: Mer regression 
\end_layout

\begin_layout Standard
Ni ska nu modellera datasetet det simulerade datasetet 
\begin_inset Quotes eld
\end_inset

NN_reg_data.csv
\begin_inset Quotes erd
\end_inset

 med neurala nätverk.
 Datasetet har en prediktor, x och y har ett icke-linjärt samband med y.
 
\end_layout

\begin_layout Enumerate
Läs in datamaterialet i R.
\end_layout

\begin_layout Enumerate
Det finns tre olika y-variabler:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
y_true
\family default
: det sanna värdet på y
\end_layout

\begin_layout Itemize

\family typewriter
y_less_noise
\family default
/
\family typewriter
y_more_noise
\family default
: 
\family typewriter
y_true
\family default
 + olika nivåer av brus.
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta de olika 
\begin_inset Formula $y$
\end_inset

 mot 
\begin_inset Formula $x$
\end_inset

.
 Hur ser sambandet ut?
\end_layout

\begin_layout Enumerate
Börja med att ha y_less_noise som er responsvariabel.
\end_layout

\begin_layout Enumerate
Dela upp data i träning/test (80/20) slumpmässigt
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Välj valfria inställningar på optimeringen.
\end_layout

\end_inset

 neurala nätverk med följande arkitekturer:
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 5 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Vilken modell presterar bäst på testdata?
\end_layout

\begin_layout Enumerate
Plotta anpassade värden för träning/test i samma plot som 
\family typewriter
y_true
\family default
.
 Ser det ut att vara en bra anpassning?
\end_layout

\begin_layout Enumerate
Om ni vill: Skatta random forest och k-nearest neighbors och jämför vilken
 modell som presterar bäst på testdata.
\end_layout

\end_deeper
\begin_layout Enumerate
Dela upp data i träning/test, där de 20% sista observationerna är testmängden
 (alltså de längst åt höger i era plottar) och resterande i träningsdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Välj valfria inställningar på optimeringen.
\end_layout

\end_inset

 neurala nätverk med följande arkitekturer:
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 5 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Vilken modell presterar bäst på testdata?
\end_layout

\begin_layout Enumerate
Plotta anpassade värden för träning/test i samma plot som 
\family typewriter
y_true
\family default
.
 Ser det ut att vara en bra anpassning?
\end_layout

\begin_layout Enumerate
Om ni vill: Skatta random forest och k-nearest neighbors och jämför vilken
 modell som presterar bäst på testdata.
\end_layout

\end_deeper
\begin_layout Enumerate
I 5) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "interpolera"
target "https://sv.wikipedia.org/wiki/Interpolation"
literal "false"

\end_inset

 en funktion, i 6) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "extrapolera"
target "https://sv.wikipedia.org/wiki/Extrapolering"
literal "false"

\end_inset

 en funktion.
 Vilken uppgift verkar lättast? Hur fungerade era modeller i de båda fallen?
 
\end_layout

\begin_layout Enumerate
Upprepa 5) och 6) fast använd 
\family typewriter
y_more_noise
\family default
.
 Hur presterar de olika modellerna när det finns mer burs i data?
\end_layout

\begin_layout Enumerate
Skatta några modeller på 
\family typewriter
y_true
\family default
 och hela datasetet som träning.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta modeller med ett gömt lager och:
\end_layout

\begin_deeper
\begin_layout Enumerate
5 noder + Relu
\end_layout

\begin_layout Enumerate
10 noder + Relu
\end_layout

\begin_layout Enumerate
Så många noder som krväs för att få en mycket bra anpassning.
 
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta observerade värden och anpassade värden i samma plot.
 Hur bra är neurala nätverk på att anpassa en godtycklig funktion?
\end_layout

\end_deeper
\end_body
\end_document
